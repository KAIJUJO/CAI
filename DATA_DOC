这是为您修订的 CAI-System V2.1 数据资产规格说明书。
这份文档已经完全废弃了旧版基于 VJP 的感知训练方案，正式确立了 “分级混合蒸馏 (Tiered Hybrid Distillation)” 和 “Leaky AS-IB (防失明摊销)” 的核心地位，并对 PAC-Bench 的数据使用红线做了严格规定。
CAI-System V2.1 数据资产规格说明书 (Revised)
项目代号: CAI-System (Causal Active Inference)版本: V2.1-Data-Spec (Grounded Distillation Edition)核心架构: 分级混合感知 (Tiered Perception) + 程序化逻辑验证 (LogicPro)
1. 模块一：感知层 (Perception / Eye Layer)
核心目标：训练 Leaky AS-IB (Amortized Spatial Information Bottleneck) 适配器。任务：利用“老师模型”（COCO Annotations & Grounded-SAM）的知识蒸馏，训练 Adapter 在单次前向传播中解耦因果实体，并利用残差机制防止冷启动失明。
1.1 数据集配置 (Data Configuration)
数据集名称,角色,原始来源,计划使用量,关键用途 (Updated)
GQA (Balanced),Tier 0 (Anchor),Scene Graph,"150,000",强监督基准 1。解析 Semantic Graph 提取核心物体 BBox，生成 Ground Truth Mask。用于建立基础的 Visual Grounding 能力。
IV-VQA (Introspective),Tier 2/3 (Distillation),Counterfactual Pairs,"60,000",核心去偏数据 1。不再使用 VJP。改为利用 Grounded-SAM 生成伪标签或全零掩码，强迫 Adapter 学习区分前景与背景，处理反事实负样本。
COCO 2014 (Annotations),Tier 1 (Gold),Pickle Lookup,N/A (查表用),金标准补充。用于 IV-VQA 数据的查表匹配。如果 IV-VQA 问题命中 COCO ID，直接使用人工标注的 Mask，替代伪标签。
SpuCo,验证集,Validation,"5,000",监控 Spurious Correlation 指标，验证去偏效果 1。
VQA-CP v2,测试集,Test,全量,评估 OOD (Out-of-Distribution) 泛化性能 1。
1.2 具体操作与预处理 (Operations - Critical Update)
1. 分级混合掩码生成 (Tiered Hybrid Masking):
Tier 0 (GQA): 解析 sceneGraphs.json $\rightarrow$ 渲染 GT Mask。
Tier 1 (IV-VQA Gold): 查 train2014_pickle 表 $\rightarrow$ 命中 ID $\rightarrow$ 调用 pycocotools 渲染 COCO GT Mask。
Tier 2 (IV-VQA Silver): 未命中 ID $\rightarrow$ 调用 GPT-4o-mini 提取实体 $\rightarrow$ 喂给 Grounded-SAM $\rightarrow$ 生成 Pseudo Mask。
Tier 3 (IV-VQA Bronze): 存在性反事实问题 (Answer=No) $\rightarrow$ 生成 全零掩码 (All-Zeros)。
2. Leaky S-IB 注入机制:
废弃： 原 VJP 梯度掩码计算 2。
新增： 软门控残差 (Leaky Bottleneck)。
预处理时： 不修改原图像素。
训练时： 在 Data Loader 中不做操作，但在模型 Forward 阶段 执行：$$Z_{input} = Z_{raw} \odot M_{pred} + \mathbf{\alpha \cdot Z_{raw}} + \epsilon \cdot (1 - M_{pred})$$
目的： $\alpha$ 项保证 LLM 在 Adapter 收敛前不会“失明”，$\epsilon$ 噪声项强迫 Adapter 最小化背景信息流。
2. 模块二：推理层 (Reasoning / Brain Layer)
核心目标：训练 LogicPro Policy + PURE Value Head 2。核心策略：利用 GPT-4o 将多模态推理题转化为 Python 代码 + 执行轨迹 (Trace)。
2.1 数据集配置 (Data Configuration)
数据集名称,角色,原始来源,合成后数量,LogicPro 合成策略与用途
MathVista (Geo/Func),核心攻坚,Multimodal Math,"40,000",利用 sympy 重写几何/函数题。训练处理坐标、距离、体积计算 3。
CLEVR,冷启动,Logic Logic,"50,000","集合运算 (Filter, Count)。逻辑简单，用于初期打通“视觉符号 $\rightarrow$ 代码变量”的接口 3。"
PAC-Bench (Reference),范式参考,Physical Task,"5,000",注意：仅参考其评估范式（如物理常识检查）3。利用 GPT-4o 合成类似的物理约束检查代码，严禁直接使用 PAC-Bench 原题进行训练，防止数据泄露。
Geometry3K,补充训练,Geometry,"5,000",补充纯几何定理的 Python 实现 3。
总数据量：约 110k 条高质量合成数据。
2.2 具体操作：LogicPro 数据合成流水线 (Synthesis Pipeline)
我们不直接使用 Text Answer，而是生成 JSON 数据 4, 5：
输入：原始 (Image, Question, Answer)。
Prompt 修正：强制要求生成 中间变量打印。
"Print intermediate variables explicitly for verification, e.g., print(f'step1_radius={r}')."
验证 (Verification)：在沙箱中执行生成的代码。
if Execute(Code) == Ground_Truth: Save() else: Discard()
Min-Form 格式化：解析执行出的 Trace，用于训练 PURE Value Head 的 Dense Reward。
合成数据样例 (JSON):
{
  "question": "Is the box large enough for the cup?",
  "program": "def solve():\n  # Step 1: Perception\n  cup_w = 5.0\n  box_w = 4.8\n  print(f'cup_width={cup_w}, box_width={box_w}')\n  # Step 2: Reasoning\n  if cup_w < box_w:\n    return 'Yes'\n  else:\n    return 'No'",
  "golden_trace": ["cup_width=5.0, box_width=4.8", "Return: No"],
  "final_answer": "No"
}
3. 模块三：执行与评估层 (Execution & Evaluation)
核心目标：验证主动感知 (Active Perception) 与逻辑严密性。
3.1 训练时的 RL 配置
算法：GRPO (Group Relative Policy Optimization) + Min-Form Reward。
动作空间：{Zoom(bbox), Crop(bbox), Generate_Code} 5。
EFE 近似：使用 PURE Value Head 预测的 Min-Form Value 作为负熵的代理。
3.2 最终评测基准 (Final Benchmarks)
基准名称,评测维度,预期优势
PAC Bench,物理/空间执行力,"LogicPro 训练的空间计算逻辑将在此发挥最大作用 (e.g., 判断物体是否装得下) 5。"
MuCR,多模态因果推理,验证 Tier 2/3 (IV-VQA) 训练出的去偏效果 5。
MMMU,综合专家能力,Baseline，确保通用能力不退化 5。
4. 总结与注意事项 (Critical Notes)
数据隔离 (Leakage Prevention)：
严禁将 PAC-Bench、MMMU 的 Test Set 图片用于感知层预训练（即使是无监督也不行）6。
合成 PAC-Bench 风格数据时，必须改变原题的具体数值或物体，只保留“物理约束检查”这一逻辑范式。
S-IB 训练修正：
彻底废弃 VJP 2。感知层的训练完全依赖 Supervised Learning (Mask Loss)。
Loss 函数必须使用 Smoothed Dice + Focal Loss，以防止 IV-VQA 全零掩码导致的数值不稳定。
LogicPro 质量控制：
代码必须可执行。不可执行的代码（Syntax Error / Runtime Error）一律视为脏数据剔除 6。

Structure
data/
├── perception/
│   ├── gqa/
│   │   ├── images/
│   │   ├── questions1.2.zip
│   │   ├── sceneGraphs.zip
│   │   └── processed/
│   │       └── gqa_masks_v1.h5  <-- (Tier 0 Output)
│   ├── iv_vqa/
│   │   ├── images/
│   │   ├── ivvqa_train_pairs.jsonl
│   │   ├── coco_annotations/
│   │   │   ├── instances_train2014.json
│   │   │   └── id_mapping.pickle
│   │   └── processed/
│   │       ├── tier1_coco_indices.json   <-- (Tier 1 Metadata)
│   │       ├── tier2_pseudo_masks/       <-- (Tier 2 Grounded-SAM Output)
│   │       └── tier3_negatives.json      <-- (Tier 3 Indices)
│
├── reasoning/
│   ├── synthesis_inputs/
│   │   ├── mathvista/
│   │   ├── clevr/
│   │   └── pac_bench_templates/
│   └── logicpro_output/
│       └── logicpro_sft_110k.jsonl       <-- (Phase 2 SFT Data)
│
└── rl/
    └── pure_rewards/
        └── step_level_labels.json        <-- (Phase 3 Reward Model Data)



